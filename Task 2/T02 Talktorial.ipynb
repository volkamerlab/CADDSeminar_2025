{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f84c0ac5",
   "metadata": {},
   "source": [
    "# T01 Â· Mordred Descriptor and MACCS Fingerprints Based SVR and RF models talktorial\n",
    "\n",
    "Authors:\n",
    "\n",
    "* Aaryan Jaitly\n",
    "* Atia Tul Wahab\n",
    "* Sadia Chaudhry\n",
    "* Youssef Mohamed Fathy\n",
    "* Zenab Khan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26631758",
   "metadata": {},
   "source": [
    "## Aim of this talktorial\n",
    "\n",
    "The main goal of this project is to use machine learning to predict LogS values (solubility). We aren't just running algorithms; we also want to understand the chemistry behind the data. We will study our dataset to make sure it makes chemical sense and is good enough to build a model on. Finally, we will compare our models to find the one that gives the most accurate and reliable results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe0308b",
   "metadata": {},
   "source": [
    "### Contents in _Theory_\n",
    "\n",
    "* Data Understanding: AqSolDB data in detail\n",
    "* What We Missed: The Importance of Data Provenance\n",
    "* The Domain Knowledge Approach\n",
    "* The Consequence of Uncurated Feature Space based on Domain Knowledge\n",
    "* The Conflict Between Hyperparameters and Data Noise\n",
    "* Conclusion: Model Performance vs. Chemical Reality\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d548c6",
   "metadata": {},
   "source": [
    "### Contents in _Practical_\n",
    "\n",
    "Contents in Practical\n",
    "\n",
    "\n",
    "* Data Preparation\n",
    "    * Loading Data\n",
    "\n",
    "    * Sanitization\n",
    "\n",
    "    * Standardization\n",
    "\n",
    "    * Descriptor Generation (Mordred and MACCS)\n",
    "\n",
    "* Machine Learning\n",
    "\n",
    "    * Cross-Validation\n",
    "\n",
    "    * Support Vector Regressor (SVR)\n",
    "\n",
    "    * Random Forest Regressor\n",
    "\n",
    "* Model Evaluation\n",
    "\n",
    "    * Metrics Comparison\n",
    "\n",
    "    * Testing on Challenge Datasets 1 & 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249e35a4",
   "metadata": {},
   "source": [
    "## Theory\n",
    "\n",
    "Building an ML model requires more than just a dataset and a label; it requires domain expertise. To successfully predict LogS, we need a large set of molecules and encodings, but we must also critically analyze the source of our data.\n",
    "\n",
    "We cannot blindly treat all solubility values as equal. We need to know if the experiments measured kinetic solubility (often used in high-throughput screening) or equilibrium solubility (the gold standard using Shake Flask). These methods yield different results for the same molecule. By understanding these experimental nuances, we can filter out noise and account for biases, leading to a more robust and scientifically accurate model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c544d518",
   "metadata": {},
   "source": [
    "### Data Understanding: AqSolDB data in detail\n",
    "In this project, we utilize the AqSolDB dataset comprising around 9000 compounds from nine different public databases. This aggregation presents a major challenge due to experimental heterogeneity, as the data was not generated via a standardized protocol. Varying experimental methods across laboratories lead to variances in the 'Ground Truth' LogS values. Our modeling approach must be robust enough to discern the underlying chemical signal amidst the noise from these disparate sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef23bad",
   "metadata": {},
   "source": [
    "### What We Missed: The Importance of Data Provenance\n",
    "We trained machine learning models using a dataset treated as a homogeneous collection, generating molecular descriptors such as Mordred and MACCS keys. However, they did not account for the experimental heterogeneity from aggregating data sources across nine different databases, which likely capped model performance due to unaddressed 'noise'.We propose that for future iterations of the project, an intensive literature search should be conducted to annotate each data point with two essential metadata columns: (1) the specific experimental protocol used, such as Shake-flask or Potentiometric, and (2) the Solubility Type (Kinetic versus Thermodynamic/Equilibrium). We believe incorporating these experimental contexts as input features or training distinct models for each solubility type could significantly reduce variance and enhance predictive accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dc514f",
   "metadata": {},
   "source": [
    "### The Domain Knowledge Approach\n",
    "We generated a wide variety of molecular descriptors through tools like Mordred and MACCS keys. We feel merely using a large number of descriptors is insufficient for effective Quantitative Structure-Activity Relationship (QSAR) modeling; instead, it is crucial to select features that closely correlate with Aqueous Solubility (LogS), including factors such as lipophilicity, molecular weight, polarity etc. The introduction of irrelevant descriptors can lead to the Curse of Dimensionality, where regularization methods (e.g., Lasso, Ridge) can mitigate, but not completely eliminate, the risks associated with extraneous features. The importance of a rigorous pre-filtering step to ensure that only descriptors with a proven correlation to solubility are included to avoid spurious correlations and excessive training time and overall model Performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f8ba39",
   "metadata": {},
   "source": [
    "### The Consequence of Uncurated Feature Space on Domain Knowledge\n",
    "A major limitation in our modeling strategy arose from training on all generated molecular descriptors without filtering, as we relied on the algorithm to find patterns within irrelevant data. This brute-force method is often inefficient in Chemoinformatics. Many included descriptors lack a physicochemical link to Aqueous Solubility (LogS), resulting in a diluted predictive signal and the challenge of differentiating meaningful chemical causation from random noise. A more effective approach would involve applying strict domain-based feature selection, retaining only descriptors known to affect solubility, thus simplifying the model and reducing overfitting risks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38486cce",
   "metadata": {},
   "source": [
    "### The Conflict Between Hyperparameters and Data Noise \n",
    "#### (Only if we use current data i.e (Noisy Data); otherwise, the aforementioned modifications may not be relevant.)\n",
    "Our support vector regression (SVR) model utilized an 80-20 training-test split and was optimized through Grid Search combined with Leave-One-Out Cross-Validation (LOOCV), identifying 'best' parameters of C=10 and Ïµ=0.1. Although these parameters minimized training error mathematically, A significant flaw in our modeling approach: prioritizing metrics over the chemical realities of the underlying data. Specifically, a high C value of 10 indicates a strict penalty for misclassification, encouraging the model to conform closely to outliers. Conversely, a low Ïµ of 0.1 imposes a narrow fitting tolerance, compelling precise alignments to target values. This strategy, applied to the AqSolDB dataset characterized by considerable experimental noise resulted in memorizing noise rather than generalizing trends. A revised method should involve the manual adjustment of Grid Search parameters, opting for a lower C and a higher Ïµ to permit greater error in fitting, thereby fostering a model that better captures the underlying solubility trends while avoiding overfitting to experimental inconsistencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f60013",
   "metadata": {},
   "source": [
    "### Conclusion: Model Performance vs. Chemical Reality\n",
    "1. In our comparative analysis, the Random Forest (RF) model yielded more favorable metrics than Support Vector Regression (SVR) on the training and initial challenge datasets. While RF appeared to handle the data variance somewhat more effectively, this advantage was relative. The significant performance drop observed for both models on Challenge Dataset 2 suggests that neither algorithm was fully capable of capturing the true solubility trends for complex, unseen compounds.\n",
    "\n",
    "2. The \"Hidden\" Data Problem: Experimental Heterogeneity The root cause of this generalization gap lies less in the algorithm and more in the data provenance. We treated AqSolDB as a homogeneous ground truth, but in reality, it is an aggregation of nine distinct databases with varying data densities. Crucially, we overlooked the experimental context treating Kinetic Solubility and Thermodynamic Equilibrium Solubility as identical targets. By merging these fundamentally different measurements into a single \"LogS\" target without distinguishing columns, we forced the model to learn from conflicting signals, effectively training on \"experimental noise.\"\n",
    "\n",
    "3. The Feature Space Trap Finally, our \"brute force\" approach to feature engineering generating all possible Mordred/MACCS descriptors diluted the predictive signal. Instead of learning from a curated set of physicochemical properties known to drive solubility (domain knowledge), the model was overwhelmed by hundreds of irrelevant features. Future iterations must prioritize quality over quantity in descriptor selection to build a model that is both accurate and chemically interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7852d27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.rdmolops import SanitizeMol\n",
    "from rdkit.Chem.MolStandardize import rdMolStandardize\n",
    "import mordred\n",
    "from mordred import descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0700554",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/AqSolDB.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b87c154",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_smiles = []\n",
    "valid_logs = []\n",
    "for i, row in df.iterrows():\n",
    "    smi = row['SMILES']\n",
    "    logS = row['LogS']\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    \n",
    "    if mol is not None:\n",
    "        try:\n",
    "            # Sanitize molecule (check valence, aromaticity, conjugation, hybridization)\n",
    "            SanitizeMol(mol)\n",
    "            \n",
    "            # Canonicalize SMILES to have consistent representation\n",
    "            clean_smi = Chem.MolToSmiles(mol, canonical=True)\n",
    "            \n",
    "            valid_smiles.append(clean_smi)\n",
    "            valid_logs.append(logS)\n",
    "        \n",
    "        except Exception as e:\n",
    "            # Skip molecules that fail sanitization\n",
    "            continue\n",
    "\n",
    "# Create a cleaned DataFrame\n",
    "clean_df = pd.DataFrame({'SMILES': valid_smiles, 'LogS': valid_logs})\n",
    "\n",
    "print(f\"âœ… Valid molecules after sanitization: {len(clean_df)} / {len(df)}\")\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b746bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_molecule(mol):\n",
    "    try:\n",
    "        # Remove salts and fragments\n",
    "        cleaner = rdMolStandardize.Cleanup(mol)\n",
    "        # Normalize functional groups\n",
    "        normalizer = rdMolStandardize.Normalize(cleaner)\n",
    "        # Reionize to standard charge states\n",
    "        reionizer = rdMolStandardize.Reionize(normalizer)\n",
    "        return reionizer\n",
    "    except:\n",
    "        return mol  # return original if fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d530e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_smiles = []\n",
    "\n",
    "for smi in df['SMILES']:\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is not None:\n",
    "        mol = standardize_molecule(mol)\n",
    "        clean_smi = Chem.MolToSmiles(mol, canonical=True)\n",
    "        standardized_smiles.append(clean_smi)\n",
    "    else:\n",
    "        standardized_smiles.append(None)\n",
    "\n",
    "df['Standardized_SMILES'] = standardized_smiles\n",
    "df = df.dropna(subset=['Standardized_SMILES']).reset_index(drop=True)\n",
    "\n",
    "print(f\"âœ… Standardized dataset saved with {len(df)} molecules\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e712a1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=\"Unnamed: 0\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4483e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96b84d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['SMILES', 'Standardized_SMILES', 'LogS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0577d4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb5dcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./data/AqSolDB_Standardized.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06419f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/AqSolDB_Standardized.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e922e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc = mordred.Calculator(descriptors, ignore_3D=True)\n",
    "mols = [rdkit.Chem.MolFromSmiles(smi) for smi in df[\"Standardized_SMILES\"]]\n",
    "mols = calc.pandas(mols=mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1b0f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "mols = mols.apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d7df64",
   "metadata": {},
   "outputs": [],
   "source": [
    "mols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf5a5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descriptors = pd.concat([df,mols],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fea3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descriptors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddfa32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descriptors.dropna(axis=1,how=\"any\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ba0380",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descriptors = df_descriptors.loc[:, (df_descriptors != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb31692",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descriptors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760b164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descriptors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d42212",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descriptors.to_csv(\"./data/AqSolDB_Standardized_Mordred.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1b7e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_descriptors[\"LogS\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fc4669",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(df_descriptors[\"LogS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887523ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_descriptors[\"LogS\"] < -8).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e052e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(df_descriptors[\"LogS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a556be18",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_descriptors[\"LogS\"] < -6.5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8343989e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descriptors = df_descriptors.select_dtypes(include='number')\n",
    "df_descriptors.drop(columns=\"LogS\", inplace=True)\n",
    "\n",
    "corr_matrix = df_descriptors.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "threshold = 0.9\n",
    "to_drop = [col for col in upper.columns if any(upper[col] > threshold)]\n",
    "df_reduced = df_descriptors.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821aeb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f67cba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb375d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = pd.concat([df,df_reduced],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd335b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4399c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced.to_csv(\"./data/AqSolDB_Standardized_Mordred_Reduced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3078ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descriptors = pd.read_csv(\"./data/AqSolDB_Standardized_Mordred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfebde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descriptors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afb3140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features (X) and target (y)\n",
    "\n",
    "X = df_descriptors.iloc[:, 3:]  # columns after first 5 are Mordred descriptors\n",
    "y = df_descriptors['LogS']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e57ea09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adae16f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be16561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only numerics\n",
    "X = X.select_dtypes(include=[np.number])  \n",
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Keep columns with at least 80% nonNaN values\n",
    "X = X.dropna(axis=1, thresh=0.8 * len(X))  \n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "print(f\"Features after cleaning: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf444d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train-test da\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, shuffle = True)\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} molecules\")\n",
    "print(f\"Test set: {X_test.shape[0]} molecules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff1ff63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "print(\"Scaling data...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eb1b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solubility distribution\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(y, bins=30, alpha=0.7, color='blue')\n",
    "plt.xlabel('LogS')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Solubility Distribution')\n",
    "plt.grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3468b370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVM model\n",
    "print(\"Training SVM model...\")\n",
    "\n",
    "svm_model = SVR(kernel = 'rbf', C = 1.0, epsilon = 0.1 , gamma = 'scale') # Got good results with defaults\n",
    "\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"SVM training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a131a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate w/ epsilon 0.1 and C = 1.0\n",
    "y_pred_test = svm_model.predict(X_test_scaled)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred_test)\n",
    "r2 = r2_score(y_test, y_pred_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "print(\n",
    "    \"SVM's Performance on Test Set:\\n\"\n",
    "    f\"  Mean Absolute Error:      {mae:.3f}\\n\"\n",
    "    f\"  RÂ²:                       {r2:.3f}\\n\"\n",
    "    f\"  Root Mean Squared Error:  {rmse:.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b5efc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred_test, alpha=0.6, s=30, color='green')\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', linewidth=2)\n",
    "plt.xlabel('Actual LogS (Test)')\n",
    "plt.ylabel('Predicted LogS (Test)')\n",
    "plt.title(f'SVM with Mordred Descriptors\\nRÂ² = {r2:.3f}, MAE = {mae:.3f}')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e252e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = {\n",
    "    'model': svm_model,\n",
    "    'scaler': scaler,\n",
    "    'feature_names': X.columns.tolist()\n",
    "}\n",
    "joblib.dump(model_data, 'svm_solubility_model.pkl')\n",
    "print(\"Model saved as 'svm_solubility_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9b10ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mordred= pd.read_csv(\"./data/AqSolDB_Standardized_Mordred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080d8036",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_mordred.iloc[:, 5:]  # columns after first 5 are Mordred descriptors  # All Mordred descriptors\n",
    "y = df_mordred['LogS']  # Solubility values\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "\n",
    "# Split into train (80%) and test (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117f6828",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Training: {X_train.shape[0]} molecules\")\n",
    "print(f\"Testing: {X_test.shape[0]} molecules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79e07fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model with optimized parameters\n",
    "model_rf = RandomForestRegressor(\n",
    "    n_estimators=100,      # 100 trees\n",
    "    max_depth=30,          # Tree depth\n",
    "    min_samples_split=5,   # Min samples to split\n",
    "    min_samples_leaf=2,    # Min samples at leaf\n",
    "    random_state=42,\n",
    "    n_jobs=-1              # Use all CPU cores\n",
    ")\n",
    "\n",
    "print(\"Training model...\")\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccf4bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training set\n",
    "y_pred_train = model_rf.predict(X_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_test = model_rf.predict(X_test)\n",
    "\n",
    "print(\"Predictions made!\")\n",
    "print(f\"\\nFirst 5 test predictions:\")\n",
    "print(f\"{'Actual':<12} {'Predicted':<12} {'Error':<10}\")\n",
    "print(\"-\" * 35)\n",
    "for i in range(5):\n",
    "    actual = y_test.iloc[i]\n",
    "    pred = y_pred_test[i]\n",
    "    error = abs(actual - pred)\n",
    "    print(f\"{actual:<12.3f} {pred:<12.3f} {error:<10.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7ccbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MODEL EVALUATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Training metrics\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "\n",
    "# Test metrics\n",
    "test_r2 = r2_score(y_test, y_pred_test)\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "print(f\"\\n TRAINING SET:\")\n",
    "print(f\"  RÂ² Score:  {train_r2:.4f}\")\n",
    "print(f\"  RMSE:      {train_rmse:.4f}\")\n",
    "print(f\"  MAE:       {train_mae:.4f}\")\n",
    "\n",
    "print(f\"\\n TEST SET (Most Important!):\")\n",
    "print(f\"  RÂ² Score:  {test_r2:.4f}\")\n",
    "print(f\"  RMSE:      {test_rmse:.4f}\")\n",
    "print(f\"  MAE:       {test_mae:.4f}\")\n",
    "\n",
    "# Check for overfitting\n",
    "gap = train_r2 - test_r2\n",
    "print(f\"\\n OVERFITTING CHECK:\")\n",
    "print(f\"  Train RÂ² - Test RÂ²: {gap:.4f}\")\n",
    "if gap < 0.05:\n",
    "    print(f\"  Good generalization!\")\n",
    "elif gap < 0.15:\n",
    "    print(f\"  Slight overfitting\")\n",
    "else:\n",
    "    print(f\"   Significant overfitting\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5adfe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"visualizations...\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Actual vs Predicted\n",
    "axes[0].scatter(y_test, y_pred_test, alpha=0.6, edgecolors='k', s=30)\n",
    "min_val = min(y_test.min(), y_pred_test.min())\n",
    "max_val = max(y_test.max(), y_pred_test.max())\n",
    "axes[0].plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect Prediction')\n",
    "axes[0].set_xlabel('Actual LogS', fontweight='bold')\n",
    "axes[0].set_ylabel('Predicted LogS', fontweight='bold')\n",
    "axes[0].set_title(f'Test Set: Actual vs Predicted\\nRÂ² = {test_r2:.4f}', fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Residuals\n",
    "residuals = y_test - y_pred_test\n",
    "axes[1].scatter(y_pred_test, residuals, alpha=0.6, edgecolors='k', s=30)\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1].set_xlabel('Predicted LogS', fontweight='bold')\n",
    "axes[1].set_ylabel('Residuals (Error)', fontweight='bold')\n",
    "axes[1].set_title(f'Residual Distribution\\nMAE = {test_mae:.4f}', fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071025f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving trained model...\")\n",
    "\n",
    "# Save model\n",
    "joblib.dump(model_rf, 'random_forest_model.pkl')\n",
    "\n",
    "print(\"Model saved as 'random_forest_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89789294",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"challenge_data_1.csv\"\n",
    "standardized_filename = \"standardized_\"+filename\n",
    "imputed_filename= \"imputed_\"+filename\n",
    "training_filename=\"imputed_AqSolDB.csv\"\n",
    "trained_model=\"svm_solubility_model.pkl\"\n",
    "image_name = filename.split(\".\")[0] + \"_prediction.png\"\n",
    "\n",
    "df = pd.read_csv(filename)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cf8947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem.rdmolops import SanitizeMol\n",
    "valid_smiles = []\n",
    "valid_logs = []\n",
    "for i, row in df.iterrows():\n",
    "    smi = row['SMILES']\n",
    "    logS = row['LogS']\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    \n",
    "    if mol is not None:\n",
    "        try:\n",
    "            # Sanitize molecule (check valence, aromaticity, conjugation, hybridization)\n",
    "            SanitizeMol(mol)\n",
    "            \n",
    "            # Canonicalize SMILES to have consistent representation\n",
    "            clean_smi = Chem.MolToSmiles(mol, canonical=True)\n",
    "            \n",
    "            valid_smiles.append(clean_smi)\n",
    "            valid_logs.append(logS)\n",
    "        \n",
    "        except Exception as e:\n",
    "            # Skip molecules that fail sanitization\n",
    "            continue\n",
    "\n",
    "# Create a cleaned DataFrame\n",
    "clean_df = pd.DataFrame({'SMILES': valid_smiles, 'LogS': valid_logs})\n",
    "\n",
    "print(f\"âœ… Valid molecules after sanitization: {len(clean_df)} / {len(df)}\")\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d1c849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_molecule(mol):\n",
    "    try:\n",
    "        # Remove salts and fragments\n",
    "        cleaner = rdMolStandardize.Cleanup(mol)\n",
    "        # Normalize functional groups\n",
    "        normalizer = rdMolStandardize.Normalize(cleaner)\n",
    "        # Reionize to standard charge states\n",
    "        reionizer = rdMolStandardize.Reionize(normalizer)\n",
    "        return reionizer\n",
    "    except:\n",
    "        return mol  # return original if fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b3536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_smiles = []\n",
    "\n",
    "for smi in df['SMILES']:\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol is not None:\n",
    "        mol = standardize_molecule(mol)\n",
    "        clean_smi = Chem.MolToSmiles(mol, canonical=True)\n",
    "        standardized_smiles.append(clean_smi)\n",
    "    else:\n",
    "        standardized_smiles.append(None)\n",
    "\n",
    "df['Standardized_SMILES'] = standardized_smiles\n",
    "df = df.dropna(subset=['Standardized_SMILES']).reset_index(drop=True)\n",
    "\n",
    "df.to_csv(standardized_filename, index=False)\n",
    "print(f\" Standardized dataset saved with {len(df)} molecules\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f348dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(standardized_filename)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd39d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Unnamed: 0' in df.columns:\n",
    "    df.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfb397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reordered = df[['SMILES', 'Standardized_SMILES', 'LogS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1f08d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc = Calculator(descriptors, ignore_3D=True)\n",
    "mols = [Chem.MolFromSmiles(smi) for smi in df[\"Standardized_SMILES\"]]\n",
    "mols = calc.pandas(mols=mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b058a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mols = mols.apply(pd.to_numeric, errors='coerce')\n",
    "mols.shape\n",
    "df_descriptors = pd.concat([df_reordered,mols],axis=1)\n",
    "df_descriptors.shape\n",
    "df_descriptors.dropna(axis=1,how=\"all\",inplace=True)\n",
    "df_descriptors.shape\n",
    "df_descriptors.dropna(axis=0, thresh=len(df_descriptors.columns) * 0.9, inplace=True)\n",
    "df_descriptors.shape\n",
    "df_descriptors.dropna(axis=1,how=\"all\",inplace=True)\n",
    "meta_info = df_reordered.loc[df_descriptors.index]\n",
    "df_descriptors.drop(columns=[\"SMILES\",\"Standardized_SMILES\",\"LogS\"],inplace=True)\n",
    "df_descriptors.isna().sum().sum()\n",
    "imp = SimpleImputer(missing_values=np.nan,strategy=\"mean\")\n",
    "imputed = imp.fit_transform(df_descriptors)\n",
    "df_mols_imputed = pd.DataFrame(imputed,columns=df_descriptors.columns,index=df_descriptors.index)\n",
    "final_df = pd.concat([meta_info, df_mols_imputed], axis=1)\n",
    "final_df.shape\n",
    "final_df.to_csv(imputed_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9784002",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(training_filename)\n",
    "\n",
    "# Get feature column names (all columns after first 5)\n",
    "feature_cols = df_train.columns[5:].tolist()\n",
    "\n",
    "print(f\"\\nðŸ“‹ Training model used {len(feature_cols)} features\")\n",
    "df1_descriptors = pd.read_csv(imputed_filename)\n",
    "# Extract only the features that were used in training\n",
    "\n",
    "missing = set(feature_cols) - set(df1_descriptors.columns)\n",
    "print(\"Missing columns:\", missing)\n",
    "\n",
    "for col in missing:\n",
    "    df1_descriptors[col] = 0\n",
    "\n",
    "X1 = df1_descriptors[feature_cols]\n",
    "\n",
    "\n",
    "# Get actual LogS values\n",
    "y1_true = df1_descriptors['LogS'].values\n",
    "\n",
    "\n",
    "print(f\"\\nâœ… Features aligned!\")\n",
    "print(f\"   Challenge 1 features: {X1.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    model_rf = joblib.load(trained_model)\n",
    "    print(\"\\nâœ… Model loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"\\nâŒ Error: Could not find 'random_forest_model.pkl'\")\n",
    "    print(\"Please make sure you saved your model in the RF training notebook using:\")\n",
    "    print(\"joblib.dump(model_rf, 'random_forest_model.pkl')\")\n",
    "    raise\n",
    "\n",
    "\n",
    "y1_pred = model_rf.predict(X1)\n",
    "\n",
    "\n",
    "print(\"\\nâœ… Predictions completed!\")\n",
    "print(f\"   Challenge 1: {len(y1_pred)} predictions\")\n",
    "\n",
    "\n",
    "def evaluate_predictions(y_true, y_pred, dataset_name):\n",
    "    \"\"\"Calculate and print evaluation metrics\"\"\"\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ðŸ“Š {dataset_name} EVALUATION\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"RÂ² Score:  {r2:.4f}\")\n",
    "    print(f\"RMSE:      {rmse:.4f}\")\n",
    "    print(f\"MAE:       {mae:.4f}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    return r2, rmse, mae\n",
    "\n",
    "r2_1, rmse_1, mae_1 = evaluate_predictions(y1_true, y1_pred, \"Challenge Data 1\")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "ax.scatter(y1_true, y1_pred, alpha=0.6, edgecolors='k', s=30)\n",
    "min_val = min(y1_true.min(), y1_pred.min())\n",
    "max_val = max(y1_true.max(), y1_pred.max())\n",
    "ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Perfect Prediction')\n",
    "ax.set_xlabel('Actual LogS', fontweight='bold')\n",
    "ax.set_ylabel('Predicted LogS', fontweight='bold')\n",
    "ax.set_title(f'Challenge 1: RÂ² = {r2_1:.4f}, MAE = {mae_1:.4f}', fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b60cdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.tight_layout()\n",
    "fig.savefig(image_name, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Figure Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba20fd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Recommended: use a conda/mamba env with rdkit installed)\n",
    "import os, json, joblib, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List, Optional\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "BASE = Path('.')\n",
    "DATA_DIR = BASE / 'data'\n",
    "SPLITS_DIR = DATA_DIR / 'splits'\n",
    "PROC_DIR = DATA_DIR / 'processed'\n",
    "MODELS_DIR = Path('models')\n",
    "FIG_DIR = Path('figures')\n",
    "RESULTS_DIR = Path('results')\n",
    "\n",
    "for d in [DATA_DIR, SPLITS_DIR, PROC_DIR, MODELS_DIR, FIG_DIR, RESULTS_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "STD_CSV_CANDIDATES = [\n",
    "    'standardized_AqSolDB.csv',\n",
    "    DATA_DIR / 'standardized_AqSolDB.csv',\n",
    "    'AqSolDB_clean.csv',\n",
    "    DATA_DIR / 'AqSolDB_clean.csv'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42acbbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Sequence\n",
    "\n",
    "def find_standardized_csv(candidates: Sequence[Path]) -> Path:\n",
    "    for c in candidates:\n",
    "        c = Path(c)\n",
    "        if c.exists():\n",
    "            return c\n",
    "    raise FileNotFoundError(\"Place 'standardized_AqSolDB.csv' next to this notebook or in ./data/\")\n",
    "\n",
    "def guess_columns(df: pd.DataFrame) -> Tuple[str, str]:\n",
    "    smiles_candidates = [c for c in df.columns if 'smiles' in c.lower()]\n",
    "    if not smiles_candidates:\n",
    "        raise ValueError(f\"No SMILES-like column found. Columns: {list(df.columns)}\")\n",
    "    smiles_col = smiles_candidates[0]\n",
    "    y_candidates = [c for c in df.columns if c.lower() in ('logs','log_s','logsol','log_solu','target','y','solubility','aqsol')]\n",
    "    if not y_candidates:\n",
    "        numeric_cols = [c for c in df.columns if c != smiles_col and pd.api.types.is_numeric_dtype(df[c])]\n",
    "        if not numeric_cols:\n",
    "            raise ValueError(\"No numeric target column found. Rename your target to 'LogS'.\")\n",
    "        y_col = numeric_cols[0]\n",
    "    else:\n",
    "        y_col = y_candidates[0]\n",
    "    return smiles_col, y_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2288d77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "std_path = find_standardized_csv(STD_CSV_CANDIDATES)\n",
    "print(f\"Using standardized data at: {std_path}\")\n",
    "df = pd.read_csv(std_path)\n",
    "print(df.head(3))\n",
    "print(f\"Rows: {len(df)} | Columns: {list(df.columns)}\")\n",
    "\n",
    "smiles_col, y_col = guess_columns(df)\n",
    "print(f\"Detected SMILES column: {smiles_col} | target column: {y_col}\")\n",
    "\n",
    "id_col = None\n",
    "for c in ['inchikey', 'InChIKey', 'canonical_smiles', 'can_smiles', 'id']:\n",
    "    if c in df.columns:\n",
    "        id_col = c\n",
    "        break\n",
    "\n",
    "if id_col is None:\n",
    "    def to_canonical(s):\n",
    "        try:\n",
    "            m = Chem.MolFromSmiles(str(s))\n",
    "            return Chem.MolToSmiles(m, canonical=True) if m is not None else None\n",
    "        except Exception:\n",
    "            return None\n",
    "    df['canonical_smiles'] = df[smiles_col].apply(to_canonical)\n",
    "    id_col = 'canonical_smiles'\n",
    "\n",
    "df = df.dropna(subset=[id_col, y_col]).copy()\n",
    "before = len(df)\n",
    "df = df.drop_duplicates(subset=[id_col]).copy()\n",
    "after = len(df)\n",
    "print(f\"De-duplicated by {id_col}: {before} -> {after}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ae5487",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unique_ids = df[id_col].tolist()\n",
    "train_ids, test_ids = train_test_split(unique_ids, test_size=0.2, random_state=SEED)\n",
    "train_ids, test_ids = set(train_ids), set(test_ids)\n",
    "\n",
    "(SPLITS_DIR / 'train_ids.txt').write_text(\"\\n\".join(sorted(train_ids)))\n",
    "(SPLITS_DIR / 'test_ids.txt').write_text(\"\\n\".join(sorted(test_ids)))\n",
    "print(\"Saved split files:\", SPLITS_DIR / 'train_ids.txt', SPLITS_DIR / 'test_ids.txt')\n",
    "\n",
    "df_train = df[df[id_col].isin(train_ids)].copy()\n",
    "df_test  = df[df[id_col].isin(test_ids)].copy()\n",
    "print(f\"Train rows: {len(df_train)} | Test rows: {len(df_test)}\")\n",
    "assert set(df_train[id_col]).isdisjoint(set(df_test[id_col]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52a1db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def maccs_fp(mol: Chem.Mol) -> Optional[np.ndarray]:\n",
    "    if mol is None:\n",
    "        return None\n",
    "    try:\n",
    "        fp = rdMolDescriptors.GetMACCSKeysFingerprint(mol)\n",
    "        return np.frombuffer(fp.ToBitString().encode('ascii'), dtype='S1').astype(np.uint8) - ord(b'0')\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def make_maccs_frame(df_part: pd.DataFrame, smiles_col: str, id_col: str, y_col: str) -> pd.DataFrame:\n",
    "    recs = []\n",
    "    for _id, s, y in zip(df_part[id_col], df_part[smiles_col], df_part[y_col]):\n",
    "        mol = Chem.MolFromSmiles(str(s))\n",
    "        arr = maccs_fp(mol)\n",
    "        if arr is None:\n",
    "            continue\n",
    "        recs.append({'_id': _id, 'y': float(y), **{f'b{i}': int(arr[i]) for i in range(len(arr))}})\n",
    "    return pd.DataFrame.from_records(recs)\n",
    "\n",
    "Xy_train = make_maccs_frame(df_train, smiles_col, id_col, y_col)\n",
    "Xy_test  = make_maccs_frame(df_test,  smiles_col, id_col, y_col)\n",
    "\n",
    "print(\"Train featurized shape:\", Xy_train.shape, \"Test shape:\", Xy_test.shape)\n",
    "bit_cols = [c for c in Xy_train.columns if c.startswith('b')]\n",
    "bit_cols.sort(key=lambda z: int(z[1:]))\n",
    "assert len(bit_cols) == 167, f\"Expected 167 MACCS bits, got {len(bit_cols)}\"\n",
    "\n",
    "X_train = Xy_train[bit_cols].to_numpy(dtype=np.uint8)\n",
    "y_train = Xy_train['y'].to_numpy(dtype=float)\n",
    "X_test  = Xy_test[bit_cols].to_numpy(dtype=np.uint8)\n",
    "y_test  = Xy_test['y'].to_numpy(dtype=float)\n",
    "\n",
    "from pathlib import Path\n",
    "PROC_DIR = Path('data/processed'); PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "np.save(PROC_DIR / 'maccs_X_train.npy', X_train)\n",
    "np.save(PROC_DIR / 'maccs_y_train.npy', y_train)\n",
    "np.save(PROC_DIR / 'maccs_X_test.npy', X_test)\n",
    "np.save(PROC_DIR / 'maccs_y_test.npy', y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2cca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "scoring = 'neg_root_mean_squared_error'\n",
    "\n",
    "rf = RandomForestRegressor(random_state=SEED, n_jobs=-1)\n",
    "rf_grid = {'n_estimators':[200,500,800], 'max_depth':[None,10,20,40], 'min_samples_leaf':[1,2,4]}\n",
    "\n",
    "svr = SVR(kernel='rbf')\n",
    "svr_grid = {'C':[1.0,10.0,100.0,300.0], 'gamma':['scale',0.01,0.03,0.1,0.3], 'epsilon':[0.01,0.05,0.1,0.2]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeb6e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import joblib, json, pandas as pd\n",
    "\n",
    "rf_search = GridSearchCV(rf, rf_grid, cv=cv, scoring=scoring, n_jobs=-1, verbose=1)\n",
    "rf_search.fit(X_train, y_train)\n",
    "print(\"Best RF params:\", rf_search.best_params_)\n",
    "\n",
    "svr_search = GridSearchCV(svr, svr_grid, cv=cv, scoring=scoring, n_jobs=-1, verbose=1)\n",
    "svr_search.fit(X_train, y_train)\n",
    "print(\"Best SVR params:\", svr_search.best_params_)\n",
    "\n",
    "Path('models').mkdir(exist_ok=True)\n",
    "joblib.dump(rf_search.best_estimator_, 'models/maccs_rf.joblib')\n",
    "joblib.dump(svr_search.best_estimator_, 'models/maccs_svr.joblib')\n",
    "\n",
    "Path('results').mkdir(exist_ok=True)\n",
    "with open('results/maccs_rf_cv.json','w') as f:\n",
    "    json.dump({'best_params': rf_search.best_params_, 'best_score_neg_rmse': float(rf_search.best_score_)}, f, indent=2)\n",
    "with open('results/maccs_svr_cv.json','w') as f:\n",
    "    json.dump({'best_params': svr_search.best_params_, 'best_score_neg_rmse': float(svr_search.best_score_)}, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307ac8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# RMSE helper: prefer new API, fall back to old\n",
    "try:\n",
    "    from sklearn.metrics import root_mean_squared_error as _rmse\n",
    "    def rmse(y, yhat): return float(_rmse(y, yhat))\n",
    "except Exception:\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    def rmse(y, yhat): return float(np.sqrt(mean_squared_error(y, yhat)))\n",
    "\n",
    "def evaluate(name, model, X, y):\n",
    "    yhat = model.predict(X)\n",
    "    return {\n",
    "        'model': name,\n",
    "        'rmse' : rmse(y, yhat),\n",
    "        'mae'  : mean_absolute_error(y, yhat),\n",
    "        'r2'   : r2_score(y, yhat),\n",
    "        'yhat' : yhat,\n",
    "    }\n",
    "\n",
    "rf_best  = joblib.load('models/maccs_rf.joblib')\n",
    "svr_best = joblib.load('models/maccs_svr.joblib')\n",
    "\n",
    "res_rf  = evaluate('MACCS-RF',  rf_best,  X_test, y_test)\n",
    "res_svr = evaluate('MACCS-SVR', svr_best, X_test, y_test)\n",
    "\n",
    "results_df = pd.DataFrame(\n",
    "    [{k:v for k,v in res_rf.items()  if k!='yhat'},\n",
    "     {k:v for k,v in res_svr.items() if k!='yhat'}]\n",
    ").sort_values('rmse')\n",
    "\n",
    "results_df.to_csv('results/maccs_test_metrics.csv', index=False)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc128d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "Path('figures').mkdir(exist_ok=True)\n",
    "\n",
    "def plot_pred_vs_true(y_true, y_pred, title, savepath):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.scatter(y_true, y_pred, alpha=0.5)\n",
    "    lims = [min(y_true.min(), y_pred.min()), max(y_true.max(), y_pred.max())]\n",
    "    plt.plot(lims, lims, '--')\n",
    "    plt.xlabel('True LogS'); plt.ylabel('Predicted LogS'); plt.title(title)\n",
    "    plt.tight_layout(); plt.savefig(savepath, dpi=200); plt.show()\n",
    "\n",
    "def plot_residuals(y_true, y_pred, title, savepath):\n",
    "    resid = y_pred - y_true\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.hist(resid, bins=30)\n",
    "    plt.xlabel('Residual (Pred - True)'); plt.ylabel('Count'); plt.title(title)\n",
    "    plt.tight_layout(); plt.savefig(savepath, dpi=200); plt.show()\n",
    "\n",
    "plot_pred_vs_true(y_test, res_rf['yhat'],  'MACCS-RF: Pred vs True',  'figures/maccs_rf_pred_vs_true.png')\n",
    "plot_residuals(y_test, res_rf['yhat'],     'MACCS-RF: Residuals',     'figures/maccs_rf_residuals.png')\n",
    "plot_pred_vs_true(y_test, res_svr['yhat'], 'MACCS-SVR: Pred vs True', 'figures/maccs_svr_pred_vs_true.png')\n",
    "plot_residuals(y_test, res_svr['yhat'],    'MACCS-SVR: Residuals',    'figures/maccs_svr_residuals.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0f28cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Minimal predict helper\n",
    "def predict_logs_for_smiles(smiles_list: List[str], model_name='rf'):\n",
    "    import joblib, numpy as np\n",
    "    path = 'models/maccs_rf.joblib' if model_name.lower()=='rf' else 'models/maccs_svr.joblib'\n",
    "    model = joblib.load(path)\n",
    "    mats = []\n",
    "    for s in smiles_list:\n",
    "        mol = Chem.MolFromSmiles(s)\n",
    "        if mol is None:\n",
    "            raise ValueError(f\"Invalid SMILES: {s}\")\n",
    "        fp = rdMolDescriptors.GetMACCSKeysFingerprint(mol)\n",
    "        arr = np.frombuffer(fp.ToBitString().encode('ascii'), dtype='S1').astype(np.uint8) - ord(b'0')\n",
    "        mats.append(arr)\n",
    "    X_new = np.vstack(mats)\n",
    "    return model.predict(X_new)\n",
    "\n",
    "# Example:\n",
    "# predict_logs_for_smiles(['CCO','c1ccccc1O'], 'rf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bb718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "manifest = {\n",
    "    'seed': SEED,\n",
    "    'notes': 'Self-created 80/20 split for MACCS pipelines',\n",
    "    'files': {\n",
    "        'split_train': 'data/splits/train_ids.txt',\n",
    "        'split_test': 'data/splits/test_ids.txt',\n",
    "        'metrics_csv': 'results/maccs_test_metrics.csv',\n",
    "        'rf_model': 'models/maccs_rf.joblib',\n",
    "        'svr_model': 'models/maccs_svr.joblib',\n",
    "        'figures': [\n",
    "            'figures/maccs_rf_pred_vs_true.png',\n",
    "            'figures/maccs_rf_residuals.png',\n",
    "            'figures/maccs_svr_pred_vs_true.png',\n",
    "            'figures/maccs_svr_residuals.png'\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "with open('results/maccs_run_manifest.json','w') as f:\n",
    "    json.dump(manifest, f, indent=2)\n",
    "print('Saved manifest â†’ results/maccs_run_manifest.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385fd37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- config: point to your challenge files ----\n",
    "CHALLENGE_FILES = [\n",
    "    \"challenge_data_1.csv\",\n",
    "    \"challenge_data_2.csv\",\n",
    "]\n",
    "\n",
    "# ---- imports ----\n",
    "import os, json, numpy as np, pandas as pd, joblib\n",
    "from pathlib import Path\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# RMSE helper (works on old/new scikit-learn)\n",
    "try:\n",
    "    from sklearn.metrics import root_mean_squared_error as _rmse\n",
    "    def rmse(y, yhat): return float(_rmse(y, yhat))\n",
    "except Exception:\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    def rmse(y, yhat): return float(np.sqrt(mean_squared_error(y, yhat)))\n",
    "\n",
    "Path(\"results\").mkdir(exist_ok=True)\n",
    "\n",
    "# ---- small helpers ----\n",
    "TARGET_NAMES = {\"logs\",\"log_s\",\"logsol\",\"log_solu\",\"target\",\"y\",\"solubility\",\"aqsol\"}\n",
    "\n",
    "def detect_cols(df: pd.DataFrame):\n",
    "    smiles_cols = [c for c in df.columns if \"smiles\" in c.lower()]\n",
    "    if not smiles_cols:\n",
    "        raise ValueError(f\"No SMILES-like column found. Columns: {list(df.columns)}\")\n",
    "    smiles_col = smiles_cols[0]\n",
    "    y_col = next((c for c in df.columns if c.lower() in TARGET_NAMES), None)\n",
    "    return smiles_col, y_col\n",
    "\n",
    "def canonicalize(s: str):\n",
    "    m = Chem.MolFromSmiles(str(s))\n",
    "    return Chem.MolToSmiles(m, canonical=True) if m is not None else None\n",
    "\n",
    "def maccs_matrix(smiles_list):\n",
    "    X = []\n",
    "    kept = []\n",
    "    for s in smiles_list:\n",
    "        m = Chem.MolFromSmiles(s)\n",
    "        if m is None: \n",
    "            continue\n",
    "        fp = rdMolDescriptors.GetMACCSKeysFingerprint(m)\n",
    "        arr = np.frombuffer(fp.ToBitString().encode(\"ascii\"), dtype=\"S1\").astype(np.uint8) - ord(b\"0\")\n",
    "        X.append(arr); kept.append(s)\n",
    "    if not X:\n",
    "        raise RuntimeError(\"No valid molecules after featurization.\")\n",
    "    X = np.vstack(X)\n",
    "    assert X.shape[1] == 167, f\"Expected 167 MACCS bits, got {X.shape[1]}\"\n",
    "    return X, kept\n",
    "\n",
    "# ---- load saved models ----\n",
    "rf  = joblib.load(\"models/maccs_rf.joblib\")\n",
    "svr = joblib.load(\"models/maccs_svr.joblib\")\n",
    "\n",
    "def evaluate_challenge(csv_path: str):\n",
    "    df_raw = pd.read_csv(csv_path)\n",
    "    smiles_col, y_col = detect_cols(df_raw)\n",
    "\n",
    "    # minimal cleaning to match training assumptions\n",
    "    df_raw[\"canonical_smiles\"] = df_raw[smiles_col].map(canonicalize)\n",
    "    df = df_raw.dropna(subset=[\"canonical_smiles\"]).drop_duplicates(\"canonical_smiles\").copy()\n",
    "\n",
    "    # features\n",
    "    X, ids = maccs_matrix(df[\"canonical_smiles\"].tolist())\n",
    "\n",
    "    # predict\n",
    "    pred_rf  = rf.predict(X)\n",
    "    pred_svr = svr.predict(X)\n",
    "\n",
    "    out_rf  = pd.DataFrame({\"canonical_smiles\": ids, \"y_pred\": pred_rf})\n",
    "    out_svr = pd.DataFrame({\"canonical_smiles\": ids, \"y_pred\": pred_svr})\n",
    "\n",
    "    metrics = {}\n",
    "    if y_col is not None and pd.api.types.is_numeric_dtype(df[y_col]):\n",
    "        y_true = df[y_col].astype(float).to_numpy()[:len(ids)]\n",
    "        metrics = {\n",
    "            \"RF\" : {\"rmse\": rmse(y_true, pred_rf),  \"mae\": float(np.mean(np.abs(y_true - pred_rf))),  \"r2\": float(r2_score(y_true, pred_rf))},\n",
    "            \"SVR\": {\"rmse\": rmse(y_true, pred_svr), \"mae\": float(np.mean(np.abs(y_true - pred_svr))), \"r2\": float(r2_score(y_true, pred_svr))},\n",
    "        }\n",
    "\n",
    "    # save\n",
    "    stem = Path(csv_path).stem\n",
    "    out_rf.to_csv(f\"results/{stem}_predictions_rf.csv\", index=False)\n",
    "    out_svr.to_csv(f\"results/{stem}_predictions_svr.csv\", index=False)\n",
    "    if metrics:\n",
    "        with open(f\"results/{stem}_metrics_maccs.json\", \"w\") as f:\n",
    "            json.dump(metrics, f, indent=2)\n",
    "\n",
    "    return metrics, out_rf.head(), out_svr.head()\n",
    "\n",
    "# ---- run on all challenge files ----\n",
    "for f in CHALLENGE_FILES:\n",
    "    print(f\"\\n=== {f} ===\")\n",
    "    m, head_rf, head_svr = evaluate_challenge(f)\n",
    "    if m:\n",
    "        print(json.dumps(m, indent=2))\n",
    "    else:\n",
    "        print(\"No ground truth column found; saved predictions only.\")\n",
    "    display(head_rf, head_svr)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teachopencadd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
